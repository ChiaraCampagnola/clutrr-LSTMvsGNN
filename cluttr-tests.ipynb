{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn, optim, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Any, Optional, Dict\n",
    "\n",
    "from data.raw_data import Instance, Data\n",
    "from data.data_utils import Dictionary, triples_to_indices, collate\n",
    "from data.dataset import CLUTRRdata\n",
    "from models.encoders import EncoderLSTM\n",
    "from models.decoders import DecoderLSTM\n",
    "from training.train import train, predict_raw, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entities 104\n",
      "Example story: [('Dwight', 'brother', 'Christopher'), ('Christopher', 'daughter', 'Lucille')]\n",
      "Example target: ('James', 'father', 'Jason')\n",
      "entity embeddings shape: torch.Size([104, 100])\n"
     ]
    }
   ],
   "source": [
    "test_data_path = ['data/clutrr-data/data_089907f8/1.2_test.csv',\n",
    "                  'data/clutrr-data/data_089907f8/1.3_test.csv',\n",
    "                 'data/clutrr-data/data_089907f8/1.4_test.csv']\n",
    "data = Data(test_paths = test_data_path)\n",
    "dictionary = Dictionary(data)\n",
    "story, target = data.train[5080].story, data.train[5000].target\n",
    "s, p, o = target\n",
    "print(f'Number of entities {dictionary.num_entities}')\n",
    "print(f'Example story: {story}')\n",
    "print(f'Example target: {target}')\n",
    "\n",
    "entity_embeddings = nn.Embedding(dictionary.num_entities, 100, sparse=True)\n",
    "relation_embeddings = nn.Embedding(dictionary.num_relations, 100, sparse=True)\n",
    "\n",
    "# Currently no backprop through embeddings\n",
    "entity_embeddings.weight.requires_grad = False\n",
    "relation_embeddings.weight.requires_grad = False\n",
    "print(f'entity embeddings shape: {entity_embeddings.weight.shape}')\n",
    "\n",
    "indices, ent, rel = triples_to_indices(dictionary, story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CLUTRRdata(data.train, dictionary)\n",
    "test_set = CLUTRRdata(data.test, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderLSTM(hidden_size = 100,\n",
    "                    entity_embeddings = entity_embeddings,\n",
    "                    relation_embeddings = relation_embeddings)\n",
    "\n",
    "decoder = DecoderLSTM(hidden_size = 100,\n",
    "                    entity_embeddings = entity_embeddings,\n",
    "                    num_relations = dictionary.num_relations)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Initial values: \n",
      "Train loss: 1.32 | Train acc: 99.24% | Test loss: 112.39 | Test acc: 62.76%\n",
      "Epoch [1/2],Train loss: 1.7048,Test loss: 155.0830 Train acc: 99.07% Test acc: 59.16%\n",
      "Epoch [2/2],Train loss: 0.9743,Test loss: 173.1465 Train acc: 99.40% Test acc: 53.45%\n",
      "Finished training\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(encoder,\n",
    "      decoder,\n",
    "      train_set,\n",
    "      test_set,\n",
    "      epochs = 2,\n",
    "      learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = ['data/clutrr-data/data_089907f8/1.4_test.csv']\n",
    "data2 = Data(test_paths = test_data_path)\n",
    "#dictionary = Dictionary(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story: [('Jenny', 'daughter', 'Anne'), ('Anne', 'father', 'Richard'), ('Richard', 'daughter', 'Kimberley'), ('Kimberley', 'uncle', 'Benjamin')]\n",
      "Target: ('Jenny', 'brother', 'Benjamin')\n",
      "Predicted relation: brother\n",
      "None\n",
      "Story: [('Cornelius', 'daughter', 'April'), ('April', 'brother', 'Frank'), ('Frank', 'daughter', 'Julia'), ('Julia', 'sister', 'Beverly')]\n",
      "Target: ('Cornelius', 'granddaughter', 'Beverly')\n",
      "Predicted relation: niece\n",
      "None\n",
      "Story: [('Christine', 'sister', 'Connie'), ('Connie', 'mother', 'Patricia'), ('Patricia', 'daughter', 'Connie'), ('Connie', 'uncle', 'Frank')]\n",
      "Target: ('Christine', 'uncle', 'Frank')\n",
      "Predicted relation: brother\n",
      "None\n",
      "Story: [('Frank', 'son', 'Charles'), ('Charles', 'sister', 'Rachel'), ('Rachel', 'sister', 'Beverly'), ('Beverly', 'uncle', 'Richard')]\n",
      "Target: ('Frank', 'brother', 'Richard')\n",
      "Predicted relation: uncle\n",
      "None\n",
      "Story: [('Jenny', 'daughter', 'Kimberley'), ('Kimberley', 'father', 'Richard'), ('Richard', 'sister', 'Patricia'), ('Patricia', 'daughter', 'Christine')]\n",
      "Target: ('Jenny', 'niece', 'Christine')\n",
      "Predicted relation: sister\n",
      "None\n",
      "Story: [('William', 'daughter', 'Connie'), ('Connie', 'brother', 'Timothy'), ('Timothy', 'mother', 'Patricia'), ('Patricia', 'daughter', 'Christine')]\n",
      "Target: ('William', 'daughter', 'Christine')\n",
      "Predicted relation: sister\n",
      "None\n",
      "Story: [('Christine', 'mother', 'Patricia'), ('Patricia', 'daughter', 'Connie'), ('Connie', 'sister', 'Christina'), ('Christina', 'brother', 'Timothy')]\n",
      "Target: ('Christine', 'brother', 'Timothy')\n",
      "Predicted relation: brother\n",
      "None\n",
      "Story: [('Frank', 'son', 'Charles'), ('Charles', 'sister', 'Beverly'), ('Beverly', 'aunt', 'Patricia'), ('Patricia', 'daughter', 'Connie')]\n",
      "Target: ('Frank', 'niece', 'Connie')\n",
      "Predicted relation: niece\n",
      "None\n",
      "Story: [('Dorothy', 'sister', 'April'), ('April', 'daughter', 'Melba'), ('Melba', 'sister', 'Sharon'), ('Sharon', 'sister', 'Lucille')]\n",
      "Target: ('Dorothy', 'niece', 'Lucille')\n",
      "Predicted relation: daughter\n",
      "None\n",
      "Story: [('Anne', 'father', 'Richard'), ('Richard', 'daughter', 'Kelley'), ('Kelley', 'sister', 'Kimberley'), ('Kimberley', 'uncle', 'Benjamin')]\n",
      "Target: ('Anne', 'uncle', 'Benjamin')\n",
      "Predicted relation: brother\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(predict_raw(data2.test[i], encoder, decoder, dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2822), 31.57894736842105)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_path = ['data/clutrr-data/data_089907f8/1.4_test.csv']\n",
    "data2 = Data(test_paths = test_data_path)\n",
    "test_set = CLUTRRdata(data2.test, dictionary)\n",
    "\n",
    "testloader = DataLoader(dataset = test_set,\n",
    "                    batch_size = 20,\n",
    "                    shuffle = True,\n",
    "                    collate_fn=collate)\n",
    "evaluate(encoder, decoder, testloader, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLUTTR-LSTMvsGNN",
   "language": "python",
   "name": "lstmvsgnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
